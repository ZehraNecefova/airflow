{"timestamp":"2025-09-03T14:10:27.173142","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-03T14:10:27.174222","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/spark_submit_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-03T14:10:27.204077","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:27.204809","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '\\n        spark-submit         --master spark://spark-master:7077         --conf spark.hadoop.fs.s3a.access.key=telcoaz         --conf spark.hadoop.fs.s3a.secret.key=Telco12345         --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000         --conf spark.hadoop.fs.s3a.path.style.access=true \\t--conf spark.eventlog.enabled=false         /opt/airflow/dags/hello_spark.py\\n        ']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:27.222290","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.361061","level":"info","event":"25/09/03 14:10:34 INFO SparkContext: Running Spark version 3.5.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.368439","level":"info","event":"25/09/03 14:10:34 INFO SparkContext: OS info Linux, 6.14.0-1012-aws, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.372808","level":"info","event":"25/09/03 14:10:34 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.601934","level":"info","event":"25/09/03 14:10:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.960343","level":"info","event":"25/09/03 14:10:34 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.964922","level":"info","event":"25/09/03 14:10:34 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.965120","level":"info","event":"25/09/03 14:10:34 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.965239","level":"info","event":"25/09/03 14:10:34 INFO SparkContext: Submitted application: ProcessingTask","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985025","level":"info","event":"25/09/03 14:10:34 INFO SparkContext: Spark configuration:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985242","level":"info","event":"spark.app.name=ProcessingTask","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985354","level":"info","event":"spark.app.startTime=1756908634330","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985445","level":"info","event":"spark.app.submitTime=1756908631149","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985544","level":"info","event":"spark.delta.logStore.class=org.apache.spark.sql.delta.storage.S3SingleDriverLogStore","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985658","level":"info","event":"spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985875","level":"info","event":"spark.eventLog.dir=/opt/spark/history","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.985997","level":"info","event":"spark.eventLog.enabled=true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.986138","level":"info","event":"spark.eventlog.enabled=false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.986257","level":"info","event":"spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.986353","level":"info","event":"spark.hadoop.fs.s3a.access.key=*********(redacted)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.986449","level":"info","event":"spark.hadoop.fs.s3a.endpoint=http://minio:9000","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.986538","level":"info","event":"spark.hadoop.fs.s3a.fast.upload=true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.986629","level":"info","event":"spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.993327","level":"info","event":"spark.hadoop.fs.s3a.multiobjectdelete.enable=true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.993578","level":"info","event":"spark.hadoop.fs.s3a.path.style.access=true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.993704","level":"info","event":"spark.hadoop.fs.s3a.secret.key=*********(redacted)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.993833","level":"info","event":"spark.history.fs.logDirectory=s3a://spark/","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.993938","level":"info","event":"spark.jars.packages=org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-avro_2.12:3.5.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994036","level":"info","event":"spark.jars.repositories=https://packages.confluent.io/maven/","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994136","level":"info","event":"spark.logConf=true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994235","level":"info","event":"spark.master=spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994335","level":"info","event":"spark.network.timeout=10000s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994438","level":"info","event":"spark.rdd.compress=True","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994535","level":"info","event":"spark.serializer.objectStreamReset=100","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994632","level":"info","event":"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994755","level":"info","event":"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994855","level":"info","event":"spark.sql.files.ignoreMissingFiles=true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.994949","level":"info","event":"spark.sql.sources.partitionOverwriteMode=dynamic","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.995045","level":"info","event":"spark.submit.deployMode=client","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:34.995144","level":"info","event":"spark.submit.pyFiles=","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.113681","level":"info","event":"25/09/03 14:10:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.129285","level":"info","event":"25/09/03 14:10:35 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.134731","level":"info","event":"25/09/03 14:10:35 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.313243","level":"info","event":"25/09/03 14:10:35 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.315562","level":"info","event":"25/09/03 14:10:35 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.320923","level":"info","event":"25/09/03 14:10:35 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.321140","level":"info","event":"25/09/03 14:10:35 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:35.325507","level":"info","event":"25/09/03 14:10:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.253274","level":"info","event":"25/09/03 14:10:36 INFO Utils: Successfully started service 'sparkDriver' on port 46619.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.356472","level":"info","event":"25/09/03 14:10:36 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.573966","level":"info","event":"25/09/03 14:10:36 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.638826","level":"info","event":"25/09/03 14:10:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.641953","level":"info","event":"25/09/03 14:10:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.656845","level":"info","event":"25/09/03 14:10:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.745624","level":"info","event":"25/09/03 14:10:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-26c99d88-2fa2-4601-991a-9d9416a29fee","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.790921","level":"info","event":"25/09/03 14:10:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:36.832047","level":"info","event":"25/09/03 14:10:36 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.064960","level":"info","event":"25/09/03 14:10:37 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.159983","level":"info","event":"25/09/03 14:10:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.495552","level":"info","event":"25/09/03 14:10:37 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.604344","level":"info","event":"25/09/03 14:10:37 INFO TransportClientFactory: Successfully created connection to spark-master/172.22.0.3:7077 after 49 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.734953","level":"info","event":"25/09/03 14:10:37 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250903141037-0006","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.739068","level":"info","event":"25/09/03 14:10:37 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250903141037-0006/0 on worker-20250903081951-172.22.0.5-43269 (172.22.0.5:43269) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.749950","level":"info","event":"25/09/03 14:10:37 INFO StandaloneSchedulerBackend: Granted executor ID app-20250903141037-0006/0 on hostPort 172.22.0.5:43269 with 2 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.782733","level":"info","event":"25/09/03 14:10:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42111.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.783420","level":"info","event":"25/09/03 14:10:37 INFO NettyBlockTransferService: Server created on 6dcc95cec7e0:42111","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.785797","level":"info","event":"25/09/03 14:10:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.804940","level":"info","event":"25/09/03 14:10:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6dcc95cec7e0, 42111, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.811891","level":"info","event":"25/09/03 14:10:37 INFO BlockManagerMasterEndpoint: Registering block manager 6dcc95cec7e0:42111 with 434.4 MiB RAM, BlockManagerId(driver, 6dcc95cec7e0, 42111, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.843527","level":"info","event":"25/09/03 14:10:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6dcc95cec7e0, 42111, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.843788","level":"info","event":"25/09/03 14:10:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6dcc95cec7e0, 42111, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:37.912964","level":"info","event":"25/09/03 14:10:37 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250903141037-0006/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:38.780937","level":"info","event":"25/09/03 14:10:38 INFO SingleEventLogFileWriter: Logging events to file:/opt/spark/history/app-20250903141037-0006.inprogress","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:39.993968","level":"info","event":"25/09/03 14:10:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:40.364948","level":"info","event":"25/09/03 14:10:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:40.371022","level":"info","event":"25/09/03 14:10:40 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpq3rrhg2z/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:42.645797","level":"info","event":"25/09/03 14:10:42 INFO InMemoryFileIndex: It took 143 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:42.906981","level":"info","event":"25/09/03 14:10:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:46.827932","level":"info","event":"25/09/03 14:10:46 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.22.0.5:55672) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:47.123293","level":"info","event":"25/09/03 14:10:47 INFO BlockManagerMasterEndpoint: Registering block manager 172.22.0.5:36665 with 434.4 MiB RAM, BlockManagerId(0, 172.22.0.5, 36665, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:49.097142","level":"info","event":"25/09/03 14:10:49 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:49.111835","level":"info","event":"25/09/03 14:10:49 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.302861","level":"info","event":"25/09/03 14:10:50 INFO CodeGenerator: Code generated in 514.930509 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.414954","level":"info","event":"25/09/03 14:10:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.501216","level":"info","event":"25/09/03 14:10:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.504135","level":"info","event":"25/09/03 14:10:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6dcc95cec7e0:42111 (size: 35.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.509890","level":"info","event":"25/09/03 14:10:50 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.522471","level":"info","event":"25/09/03 14:10:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.755963","level":"info","event":"25/09/03 14:10:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.795867","level":"info","event":"25/09/03 14:10:50 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.796086","level":"info","event":"25/09/03 14:10:50 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.797909","level":"info","event":"25/09/03 14:10:50 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.798893","level":"info","event":"25/09/03 14:10:50 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.806923","level":"info","event":"25/09/03 14:10:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.935919","level":"info","event":"25/09/03 14:10:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.941663","level":"info","event":"25/09/03 14:10:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.941902","level":"info","event":"25/09/03 14:10:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6dcc95cec7e0:42111 (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.944543","level":"info","event":"25/09/03 14:10:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.967110","level":"info","event":"25/09/03 14:10:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:50.968913","level":"info","event":"25/09/03 14:10:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:51.006764","level":"info","event":"25/09/03 14:10:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.22.0.5, executor 0, partition 0, PROCESS_LOCAL, 8217 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:51.603455","level":"info","event":"25/09/03 14:10:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.22.0.5:36665 (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:53.885779","level":"info","event":"25/09/03 14:10:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.22.0.5:36665 (size: 35.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.394840","level":"info","event":"25/09/03 14:10:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4404 ms on 172.22.0.5 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.400931","level":"info","event":"25/09/03 14:10:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.406653","level":"info","event":"25/09/03 14:10:55 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.564 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.419360","level":"info","event":"25/09/03 14:10:55 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.422193","level":"info","event":"25/09/03 14:10:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.429305","level":"info","event":"25/09/03 14:10:55 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.673056 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.921839","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.922051","level":"info","event":"  File \"/opt/airflow/dags/hello_spark.py\", line 23, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.922156","level":"info","event":"    df = df.withColumn(\"age\", (datediff(current_date(), col(\"`Date of birth`\")) / 365.25).cast(\"integer\"))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.922248","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 5170, in withColumn","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.922337","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.922432","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.929475","level":"info","event":"pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column or function parameter with name `Date of birth` cannot be resolved. ;","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.929686","level":"info","event":"'Project [cast((datediff(current_date(Some(Etc/UTC)), 'Date of birth) / 365.25) as int) AS age#15]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.929805","level":"info","event":"+- Relation [] csv","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:55.929912","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.008959","level":"info","event":"25/09/03 14:10:56 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.009229","level":"info","event":"25/09/03 14:10:56 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.024856","level":"info","event":"25/09/03 14:10:56 INFO SparkUI: Stopped Spark web UI at http://6dcc95cec7e0:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.033287","level":"info","event":"25/09/03 14:10:56 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.034936","level":"info","event":"25/09/03 14:10:56 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.083757","level":"info","event":"25/09/03 14:10:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.107858","level":"info","event":"25/09/03 14:10:56 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.111952","level":"info","event":"25/09/03 14:10:56 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.125964","level":"info","event":"25/09/03 14:10:56 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.133896","level":"info","event":"25/09/03 14:10:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.147643","level":"info","event":"25/09/03 14:10:56 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.148030","level":"info","event":"25/09/03 14:10:56 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.151534","level":"info","event":"25/09/03 14:10:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-1e60700e-7d6c-494d-858c-beb0336a7bf6","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.171679","level":"info","event":"25/09/03 14:10:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-d32234f0-814e-4c18-9915-c1f9af0fc157","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.200561","level":"info","event":"25/09/03 14:10:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-1e60700e-7d6c-494d-858c-beb0336a7bf6/pyspark-366ca194-1637-4303-a201-34704899df55","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.286236","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-03T14:10:56.287109","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":838,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1130,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/operators/bash.py","lineno":233,"name":"execute"}]}]}
